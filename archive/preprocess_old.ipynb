{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "\n",
    "This notebook will create the necessary input files before we can start training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine \n",
    "import string\n",
    "import spacy\n",
    "import re\n",
    "from datetime import date, datetime, timedelta\n",
    "import random\n",
    "from sklearn.model_selection import GroupShuffleSplit, StratifiedShuffleSplit\n",
    "\n",
    "gpu_access = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADMISSIONS.csv\t     D_ICD_PROCEDURES.csv    PATIENTS.csv\r\n",
      "CALLOUT.csv\t     D_ITEMS.csv\t     PRESCRIPTIONS.csv\r\n",
      "CAREGIVERS.csv\t     D_LABITEMS.csv\t     PROCEDUREEVENTS_MV.csv\r\n",
      "CHARTEVENTS.csv      ICUSTAYS.csv\t     PROCEDURES_ICD.csv\r\n",
      "CPTEVENTS.csv\t     INPUTEVENTS_CV.csv      SERVICES.csv\r\n",
      "DATETIMEEVENTS.csv   INPUTEVENTS_MV.csv      TRANSFERS.csv\r\n",
      "DIAGNOSES_ICD.csv    LABEVENTS.csv\t     preprocessed\r\n",
      "DRGCODES.csv\t     MICROBIOLOGYEVENTS.csv  robots.txt.tmp\r\n",
      "D_CPT.csv\t     NOTEEVENTS.csv\r\n",
      "D_ICD_DIAGNOSES.csv  OUTPUTEVENTS.csv\r\n"
     ]
    }
   ],
   "source": [
    "# show the csv files that correspond to tables in the database\n",
    "\n",
    "!ls /mimic/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the mimic database and set the search path to the 'mimiciii' schema\n",
    "\n",
    "dbschema='mimiciii'\n",
    "cnx = create_engine('postgresql+psycopg2://aa5118:mimic@localhost:5432/mimic',\n",
    "                    connect_args={'options': '-csearch_path={}'.format(dbschema)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "      <th>text_avg_chars</th>\n",
       "      <th>time_provided</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Case Management</td>\n",
       "      <td>967</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consult</td>\n",
       "      <td>98</td>\n",
       "      <td>6040.0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>59652</td>\n",
       "      <td>9620.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECG</td>\n",
       "      <td>209051</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Echo</td>\n",
       "      <td>45794</td>\n",
       "      <td>2320.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>General</td>\n",
       "      <td>8301</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>8260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nursing</td>\n",
       "      <td>223556</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>222172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>822497</td>\n",
       "      <td>800.0</td>\n",
       "      <td>822497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nutrition</td>\n",
       "      <td>9418</td>\n",
       "      <td>2430.0</td>\n",
       "      <td>9411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pharmacy</td>\n",
       "      <td>103</td>\n",
       "      <td>2580.0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Physician</td>\n",
       "      <td>141624</td>\n",
       "      <td>7140.0</td>\n",
       "      <td>141048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Radiology</td>\n",
       "      <td>522279</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>522279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Rehab Services</td>\n",
       "      <td>5431</td>\n",
       "      <td>3120.0</td>\n",
       "      <td>5429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Respiratory</td>\n",
       "      <td>31739</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>31703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Social Work</td>\n",
       "      <td>2670</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category   count  text_avg_chars  time_provided\n",
       "0    Case Management      967          1120.0            967\n",
       "1             Consult      98          6040.0             98\n",
       "2   Discharge summary   59652          9620.0              0\n",
       "3                 ECG  209051           210.0              0\n",
       "4                Echo   45794          2320.0              0\n",
       "5             General    8301          1560.0           8260\n",
       "6             Nursing  223556          1790.0         222172\n",
       "7       Nursing/other  822497           800.0         822497\n",
       "8           Nutrition    9418          2430.0           9411\n",
       "9            Pharmacy     103          2580.0            102\n",
       "10         Physician   141624          7140.0         141048\n",
       "11          Radiology  522279          1740.0         522279\n",
       "12     Rehab Services    5431          3120.0           5429\n",
       "13       Respiratory    31739          1360.0          31703\n",
       "14        Social Work    2670          2160.0           2648"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# breakdown of note categories showing the number of notes, average number of characters\n",
    "# and the number of notes in each category where the note time was provided\n",
    "\n",
    "df_summary = pd.read_sql_query('''\n",
    "  SELECT \n",
    "      category,\n",
    "      COUNT(category),\n",
    "      ROUND(AVG(LENGTH(text)),-1) AS text_avg_chars,\n",
    "      COUNT(charttime) AS time_provided\n",
    "  FROM noteevents\n",
    "  GROUP BY category\n",
    "''', cnx)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charttime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [charttime]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirming that the dataframe output should have 0 rows\n",
    "\n",
    "blah = \"'Discharge summary'\"\n",
    "df_temp = pd.read_sql_query('''\n",
    "  SELECT charttime FROM noteevents WHERE category = ''' + blah + ''' AND charttime IS NOT NULL\n",
    "''', cnx)\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1657776, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>category</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>row_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>age_at_noteevent</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>2101-10-15</td>\n",
       "      <td>768442</td>\n",
       "      <td>2101-10-15 13:59:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>[**2101-10-15**] 1:59 PM\\n CHEST (PORTABLE AP)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>2101-10-06</td>\n",
       "      <td>767724</td>\n",
       "      <td>2101-10-06 18:02:00</td>\n",
       "      <td>76.0</td>\n",
       "      <td>[**2101-10-6**] 6:02 PM\\n CHEST (PORTABLE AP) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>2101-10-22</td>\n",
       "      <td>1260688</td>\n",
       "      <td>2101-10-22 04:36:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Resp. Care Note\\nPt intubated and vented on se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>2101-10-24</td>\n",
       "      <td>1260696</td>\n",
       "      <td>2101-10-24 05:53:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>MICU NPN 7PM-7AM:\\nNeuro: Pt is sleeping most ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>2101-10-21</td>\n",
       "      <td>1260685</td>\n",
       "      <td>2101-10-21 14:27:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>MICU NSG PROG NOTE: days\\nRemains stable on hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id        dob gender       category  chartdate   row_id  \\\n",
       "0           3 2025-04-11      M      Radiology 2101-10-15   768442   \n",
       "1           3 2025-04-11      M      Radiology 2101-10-06   767724   \n",
       "2           3 2025-04-11      M  Nursing/other 2101-10-22  1260688   \n",
       "3           3 2025-04-11      M  Nursing/other 2101-10-24  1260696   \n",
       "4           3 2025-04-11      M  Nursing/other 2101-10-21  1260685   \n",
       "\n",
       "            charttime  age_at_noteevent  \\\n",
       "0 2101-10-15 13:59:00              77.0   \n",
       "1 2101-10-06 18:02:00              76.0   \n",
       "2 2101-10-22 04:36:00              77.0   \n",
       "3 2101-10-24 05:53:00              77.0   \n",
       "4 2101-10-21 14:27:00              77.0   \n",
       "\n",
       "                                                text  \n",
       "0  [**2101-10-15**] 1:59 PM\\n CHEST (PORTABLE AP)...  \n",
       "1  [**2101-10-6**] 6:02 PM\\n CHEST (PORTABLE AP) ...  \n",
       "2  Resp. Care Note\\nPt intubated and vented on se...  \n",
       "3  MICU NPN 7PM-7AM:\\nNeuro: Pt is sleeping most ...  \n",
       "4  MICU NSG PROG NOTE: days\\nRemains stable on hi...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# main dataframe - join 'patients' to 'noteevents' and only look at adults (>=15yo)\n",
    "\n",
    "df_main = pd.read_sql_query('''\n",
    "  SELECT\n",
    "      p.subject_id, p.dob, p.gender,\n",
    "      n.category, n.chartdate, n.row_id, n.charttime,\n",
    "      ROUND((cast(chartdate as date) - cast(dob as date)) / 365.242,0)\n",
    "          AS age_at_noteevent,\n",
    "      n.text\n",
    "  FROM patients p \n",
    "  INNER JOIN noteevents n \n",
    "  ON p.subject_id = n.subject_id\n",
    "  WHERE ROUND((cast(chartdate as date) - cast(dob as date)) / 365.242,0) > 14\n",
    "  ORDER BY subject_id\n",
    "  --LIMIT 10000;\n",
    "''', cnx)\n",
    "print(df_main.shape)\n",
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to preprocess the text from the 'noteevents' table and tokenise using the spaCy tokenizer\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "counter = 0\n",
    "def tokenise_text(text):\n",
    "    global counter\n",
    "    \n",
    "    text = re.sub(r'([0-9])-([0-9][0-9]?)-([0-9])',r'\\1/\\2/\\3',text)\n",
    "    text = text.replace(\"[**\",\"[\").replace(\"**]\",\"]\")\n",
    "    \n",
    "    #text = text.lower()\n",
    "    tokens = nlp.tokenizer(text)\n",
    "    tokenised_text = \"\"\n",
    "    \n",
    "    for token in tokens:\n",
    "        tokenised_text = tokenised_text + str(token) + \" \"\n",
    "    \n",
    "    tokenised_text = tokenised_text.replace(\"\\n\",\" <par> \").replace(\"\\r\",\" <par> \")\n",
    "    tokenised_text = ' '.join(tokenised_text.split())\n",
    "    \n",
    "    counter += 1\n",
    "    if (counter % 10000) == 0:\n",
    "        print (counter)\n",
    "    \n",
    "    return tokenised_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "580000\n",
      "590000\n",
      "600000\n",
      "610000\n",
      "620000\n",
      "630000\n",
      "640000\n",
      "650000\n",
      "660000\n",
      "670000\n",
      "680000\n",
      "690000\n",
      "700000\n",
      "710000\n",
      "720000\n",
      "730000\n",
      "740000\n",
      "750000\n",
      "760000\n",
      "770000\n",
      "780000\n",
      "790000\n",
      "800000\n",
      "810000\n",
      "820000\n",
      "830000\n",
      "840000\n",
      "850000\n",
      "860000\n",
      "870000\n",
      "880000\n",
      "890000\n",
      "900000\n",
      "910000\n",
      "920000\n",
      "930000\n",
      "940000\n",
      "950000\n",
      "960000\n",
      "970000\n",
      "980000\n",
      "990000\n",
      "1000000\n",
      "1010000\n",
      "1020000\n",
      "1030000\n",
      "1040000\n",
      "1050000\n",
      "1060000\n",
      "1070000\n",
      "1080000\n",
      "1090000\n",
      "1100000\n",
      "1110000\n",
      "1120000\n",
      "1130000\n",
      "1140000\n",
      "1150000\n",
      "1160000\n",
      "1170000\n",
      "1180000\n",
      "1190000\n",
      "1200000\n",
      "1210000\n",
      "1220000\n",
      "1230000\n",
      "1240000\n",
      "1250000\n",
      "1260000\n",
      "1270000\n",
      "1280000\n",
      "1290000\n",
      "1300000\n",
      "1310000\n",
      "1320000\n",
      "1330000\n",
      "1340000\n",
      "1350000\n",
      "1360000\n",
      "1370000\n",
      "1380000\n",
      "1390000\n",
      "1400000\n",
      "1410000\n",
      "1420000\n",
      "1430000\n",
      "1440000\n",
      "1450000\n",
      "1460000\n",
      "1470000\n",
      "1480000\n",
      "1490000\n",
      "1500000\n",
      "1510000\n",
      "1520000\n",
      "1530000\n",
      "1540000\n",
      "1550000\n",
      "1560000\n",
      "1570000\n",
      "1580000\n",
      "1590000\n",
      "1600000\n",
      "1610000\n",
      "1620000\n",
      "1630000\n",
      "1640000\n",
      "1650000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>category</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>row_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>age_at_noteevent</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>2101-10-15</td>\n",
       "      <td>768442</td>\n",
       "      <td>2101-10-15 13:59:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>[ 2101/10/15 ] 1:59 PM &lt;par&gt; CHEST ( PORTABLE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>2101-10-06</td>\n",
       "      <td>767724</td>\n",
       "      <td>2101-10-06 18:02:00</td>\n",
       "      <td>76.0</td>\n",
       "      <td>[ 2101/10/6 ] 6:02 PM &lt;par&gt; CHEST ( PORTABLE A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>2101-10-22</td>\n",
       "      <td>1260688</td>\n",
       "      <td>2101-10-22 04:36:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Resp . Care Note &lt;par&gt; Pt intubated and vented...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>2101-10-24</td>\n",
       "      <td>1260696</td>\n",
       "      <td>2101-10-24 05:53:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>MICU NPN 7PM-7AM : &lt;par&gt; Neuro : Pt is sleepin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>2101-10-21</td>\n",
       "      <td>1260685</td>\n",
       "      <td>2101-10-21 14:27:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>MICU NSG PROG NOTE : days &lt;par&gt; Remains stable...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id        dob gender       category  chartdate   row_id  \\\n",
       "0           3 2025-04-11      M      Radiology 2101-10-15   768442   \n",
       "1           3 2025-04-11      M      Radiology 2101-10-06   767724   \n",
       "2           3 2025-04-11      M  Nursing/other 2101-10-22  1260688   \n",
       "3           3 2025-04-11      M  Nursing/other 2101-10-24  1260696   \n",
       "4           3 2025-04-11      M  Nursing/other 2101-10-21  1260685   \n",
       "\n",
       "            charttime  age_at_noteevent  \\\n",
       "0 2101-10-15 13:59:00              77.0   \n",
       "1 2101-10-06 18:02:00              76.0   \n",
       "2 2101-10-22 04:36:00              77.0   \n",
       "3 2101-10-24 05:53:00              77.0   \n",
       "4 2101-10-21 14:27:00              77.0   \n",
       "\n",
       "                                                text  \n",
       "0  [ 2101/10/15 ] 1:59 PM <par> CHEST ( PORTABLE ...  \n",
       "1  [ 2101/10/6 ] 6:02 PM <par> CHEST ( PORTABLE A...  \n",
       "2  Resp . Care Note <par> Pt intubated and vented...  \n",
       "3  MICU NPN 7PM-7AM : <par> Neuro : Pt is sleepin...  \n",
       "4  MICU NSG PROG NOTE : days <par> Remains stable...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply tokenising function\n",
    "\n",
    "df_main[\"text\"] = df_main[\"text\"].apply(tokenise_text)\n",
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "580000\n",
      "590000\n",
      "600000\n",
      "610000\n",
      "620000\n",
      "630000\n",
      "640000\n",
      "650000\n",
      "660000\n",
      "670000\n",
      "680000\n",
      "690000\n",
      "700000\n",
      "710000\n",
      "720000\n",
      "730000\n",
      "740000\n",
      "750000\n",
      "760000\n",
      "770000\n",
      "780000\n",
      "790000\n",
      "800000\n",
      "810000\n",
      "820000\n",
      "830000\n",
      "840000\n",
      "850000\n",
      "860000\n",
      "870000\n",
      "880000\n",
      "890000\n",
      "900000\n",
      "910000\n",
      "920000\n",
      "930000\n",
      "940000\n",
      "950000\n",
      "960000\n",
      "970000\n",
      "980000\n",
      "990000\n",
      "1000000\n",
      "1010000\n",
      "1020000\n",
      "1030000\n",
      "1040000\n",
      "1050000\n",
      "1060000\n",
      "1070000\n",
      "1080000\n",
      "1090000\n",
      "1100000\n",
      "1110000\n",
      "1120000\n",
      "1130000\n",
      "1140000\n",
      "1150000\n",
      "1160000\n",
      "1170000\n",
      "1180000\n",
      "1190000\n",
      "1200000\n",
      "1210000\n",
      "1220000\n",
      "1230000\n",
      "1240000\n",
      "1250000\n",
      "1260000\n",
      "1270000\n",
      "1280000\n",
      "1290000\n",
      "1300000\n",
      "1310000\n",
      "1320000\n",
      "1330000\n",
      "1340000\n",
      "1350000\n",
      "1360000\n",
      "1370000\n",
      "1380000\n",
      "1390000\n",
      "1400000\n",
      "1410000\n",
      "1420000\n",
      "1430000\n",
      "1440000\n",
      "1450000\n",
      "1460000\n",
      "1470000\n",
      "1480000\n",
      "1490000\n",
      "1500000\n",
      "1510000\n",
      "1520000\n",
      "1530000\n",
      "1540000\n",
      "1550000\n",
      "1560000\n",
      "1570000\n",
      "1580000\n",
      "1590000\n",
      "1600000\n",
      "1610000\n",
      "1620000\n",
      "1630000\n",
      "1640000\n",
      "1650000\n",
      "(1657776, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>category</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>row_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>age_at_noteevent</th>\n",
       "      <th>text</th>\n",
       "      <th>hint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>2101-10-15</td>\n",
       "      <td>768442</td>\n",
       "      <td>2101-10-15 13:59:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>[ 2101/10/15 ] 1:59 PM &lt;par&gt; CHEST ( PORTABLE ...</td>\n",
       "      <td>[ 2101/10/15 ] 1:59 PM &lt;par&gt; CHEST ( PORTABLE AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>2101-10-06</td>\n",
       "      <td>767724</td>\n",
       "      <td>2101-10-06 18:02:00</td>\n",
       "      <td>76.0</td>\n",
       "      <td>[ 2101/10/6 ] 6:02 PM &lt;par&gt; CHEST ( PORTABLE A...</td>\n",
       "      <td>[ 2101/10/6 ] 6:02 PM &lt;par&gt; CHEST ( PORTABLE AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>2101-10-22</td>\n",
       "      <td>1260688</td>\n",
       "      <td>2101-10-22 04:36:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Resp . Care Note &lt;par&gt; Pt intubated and vented...</td>\n",
       "      <td>Resp . Care Note &lt;par&gt; Pt intubated and vented on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>2101-10-24</td>\n",
       "      <td>1260696</td>\n",
       "      <td>2101-10-24 05:53:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>MICU NPN 7PM-7AM : &lt;par&gt; Neuro : Pt is sleepin...</td>\n",
       "      <td>MICU NPN 7PM-7AM : &lt;par&gt; Neuro : Pt is sleeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>M</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>2101-10-21</td>\n",
       "      <td>1260685</td>\n",
       "      <td>2101-10-21 14:27:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>MICU NSG PROG NOTE : days &lt;par&gt; Remains stable...</td>\n",
       "      <td>MICU NSG PROG NOTE : days &lt;par&gt; Remains stable on</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id        dob gender       category  chartdate   row_id  \\\n",
       "0           3 2025-04-11      M      Radiology 2101-10-15   768442   \n",
       "1           3 2025-04-11      M      Radiology 2101-10-06   767724   \n",
       "2           3 2025-04-11      M  Nursing/other 2101-10-22  1260688   \n",
       "3           3 2025-04-11      M  Nursing/other 2101-10-24  1260696   \n",
       "4           3 2025-04-11      M  Nursing/other 2101-10-21  1260685   \n",
       "\n",
       "            charttime  age_at_noteevent  \\\n",
       "0 2101-10-15 13:59:00              77.0   \n",
       "1 2101-10-06 18:02:00              76.0   \n",
       "2 2101-10-22 04:36:00              77.0   \n",
       "3 2101-10-24 05:53:00              77.0   \n",
       "4 2101-10-21 14:27:00              77.0   \n",
       "\n",
       "                                                text  \\\n",
       "0  [ 2101/10/15 ] 1:59 PM <par> CHEST ( PORTABLE ...   \n",
       "1  [ 2101/10/6 ] 6:02 PM <par> CHEST ( PORTABLE A...   \n",
       "2  Resp . Care Note <par> Pt intubated and vented...   \n",
       "3  MICU NPN 7PM-7AM : <par> Neuro : Pt is sleepin...   \n",
       "4  MICU NSG PROG NOTE : days <par> Remains stable...   \n",
       "\n",
       "                                                hint  \n",
       "0   [ 2101/10/15 ] 1:59 PM <par> CHEST ( PORTABLE AP  \n",
       "1    [ 2101/10/6 ] 6:02 PM <par> CHEST ( PORTABLE AP  \n",
       "2  Resp . Care Note <par> Pt intubated and vented on  \n",
       "3    MICU NPN 7PM-7AM : <par> Neuro : Pt is sleeping  \n",
       "4  MICU NSG PROG NOTE : days <par> Remains stable on  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the first n tokens of the text as a hint\n",
    "counter = 0\n",
    "def produce_hint(text):\n",
    "    global counter\n",
    "    l = text.split()\n",
    "    counter += 1\n",
    "    if (counter % 10000) == 0:\n",
    "        print (counter)\n",
    "    return ' '.join(l[:10]) # first 10 tokens\n",
    "\n",
    "df_main['hint'] = df_main['text'].map(lambda x: produce_hint(x))\n",
    "print(df_main.shape)\n",
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patients above 89 years of age had their dob modified to be 300 years old at time of first event for privacy reasons\n",
    "# change their age to instead be 90\n",
    "\n",
    "df_main.loc[df_main['age_at_noteevent'] > 200, 'age_at_noteevent'] = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 500. loss_train: 0.027640069201780113 | loss_val: 0.13381721657474313 | loss_test: 0.12445111385619839 | \n",
      "Group 1000. loss_train: 0.01350923114040861 | loss_val: 0.03312332620990509 | loss_test: 0.03240166600973489 | \n",
      "Group 1500. loss_train: -0.0044589494895938 | loss_val: -0.014220263683998952 | loss_test: -0.011229096139819834 | \n",
      "Group 2000. loss_train: -0.005815651045035814 | loss_val: -0.018237003050632736 | loss_test: -0.01429010167491157 | \n",
      "Group 2500. loss_train: 0.0035240653813290476 | loss_val: 0.014032928210995377 | loss_test: 0.007416240565002041 | \n",
      "Group 3000. loss_train: 0.0007004353970999297 | loss_val: 0.004157681908064318 | loss_test: 0.0014213532946655313 | \n",
      "Group 3500. loss_train: 0.0009494846828195252 | loss_val: 0.0034881720080541757 | loss_test: 0.0027326355436606423 | \n",
      "Group 4000. loss_train: -0.005159161275861175 | loss_val: -0.0177335259190913 | loss_test: -0.014698573124395974 | \n",
      "Group 4500. loss_train: -0.00015324673093914943 | loss_val: -0.0011632706410359852 | loss_test: -0.00039231623447037587 | \n",
      "Group 5000. loss_train: 0.00014740869025766282 | loss_val: 0.0004116967197914023 | loss_test: 0.0003863746166356328 | \n",
      "Group 5500. loss_train: 0.0013193734362070175 | loss_val: 0.0036102846377637494 | loss_test: 0.0034052027352231063 | \n",
      "Group 6000. loss_train: 0.0007037639280063682 | loss_val: 0.0018325669784893827 | loss_test: 0.0018122749702659776 | \n",
      "Group 6500. loss_train: 0.0002562297936784303 | loss_val: 0.0007014359483972983 | loss_test: 0.0006374054642629625 | \n",
      "Group 7000. loss_train: -0.0002625908952900721 | loss_val: -0.0010315414521514658 | loss_test: -0.0006380636170938813 | \n",
      "Group 7500. loss_train: -0.0007290378032194241 | loss_val: -0.002683740005460891 | loss_test: -0.0017838016137318188 | \n",
      "Group 8000. loss_train: 0.000786729707554932 | loss_val: 0.0031140180612913263 | loss_test: 0.0018167357863617434 | \n",
      "Group 8500. loss_train: 4.39545928745268e-05 | loss_val: 0.00016527323371099214 | loss_test: 9.707074032638862e-05 | \n",
      "Group 9000. loss_train: 0.0002793965062350529 | loss_val: 0.0009689087693703718 | loss_test: 0.0006902057712861192 | \n",
      "Group 9500. loss_train: -0.0001659138978530137 | loss_val: -0.0007992838129530459 | loss_test: -0.00037769229033070447 | \n",
      "Group 10000. loss_train: 0.00034773109938347795 | loss_val: 0.001206025982024731 | loss_test: 0.0009412221501964278 | \n",
      "Group 10500. loss_train: 6.08140370164212e-05 | loss_val: 0.0002647965464174753 | loss_test: 0.00014707050162656316 | \n",
      "Group 11000. loss_train: 1.969098998615035e-05 | loss_val: 0.00016254200721359488 | loss_test: 1.2863402643975733e-05 | \n",
      "Group 11500. loss_train: 0.00016004258306787984 | loss_val: 0.0006840757540395395 | loss_test: 0.0003640236718199049 | \n",
      "Group 12000. loss_train: 8.490637485283987e-06 | loss_val: 2.4076310739333453e-05 | loss_test: 2.7135713772009e-05 | \n",
      "Group 12500. loss_train: 8.29655483760773e-05 | loss_val: 0.0003790677842067263 | loss_test: 0.00015341678660177552 | \n",
      "Group 13000. loss_train: -6.980745297790893e-05 | loss_val: -0.00026698949752754827 | loss_test: -0.00017290396857097014 | \n",
      "Group 13500. loss_train: 2.2348661812483563e-05 | loss_val: 0.00021365663472309052 | loss_test: -8.8135634813863e-06 | \n",
      "Group 14000. loss_train: -2.3803672098675354e-06 | loss_val: 9.33597954227991e-06 | loss_test: -1.5259982829747272e-05 | \n",
      "Group 14500. loss_train: 0.00010523349723784661 | loss_val: 0.00030372375978772296 | loss_test: 0.00032698924660056323 | \n",
      "Group 15000. loss_train: 2.5407567137540095e-05 | loss_val: 8.098650358369382e-05 | loss_test: 5.500789244257093e-05 | \n",
      "Group 15500. loss_train: -0.00016413424035921186 | loss_val: -0.0006799466658214934 | loss_test: -0.0003604829544691177 | \n",
      "Group 16000. loss_train: 2.096538558032238e-05 | loss_val: 5.204872449569724e-05 | loss_test: 6.430059364690012e-05 | \n",
      "Group 16500. loss_train: 0.00011823278762753696 | loss_val: 0.000432863044572643 | loss_test: 0.0003089171524543875 | \n",
      "Group 17000. loss_train: 7.48001297026226e-05 | loss_val: 0.0002028966064130524 | loss_test: 0.00021268477438086926 | \n",
      "Group 17500. loss_train: 0.0001417877718017499 | loss_val: 0.00038463131524077334 | loss_test: 0.0003717053022835883 | \n",
      "Group 18000. loss_train: 0.0003644056796039743 | loss_val: 0.00107230247465904 | loss_test: 0.0010088160355667202 | \n",
      "Group 18500. loss_train: 0.00012035877222517541 | loss_val: 0.00021553868514137227 | loss_test: 0.00036392774705912523 | \n",
      "Group 19000. loss_train: 0.00013963305858666678 | loss_val: 0.00041616082540614296 | loss_test: 0.000399071992049713 | \n",
      "Group 19500. loss_train: 9.848378081260583e-05 | loss_val: 0.00029369079723669196 | loss_test: 0.0002795439244330807 | \n",
      "Group 20000. loss_train: -1.4754176804483192e-05 | loss_val: -0.00012377510326985001 | loss_test: -6.0989194357717025e-06 | \n",
      "Group 20500. loss_train: 2.349742048872626e-05 | loss_val: 0.00012651993866868926 | loss_test: 3.967309377633098e-05 | \n",
      "Group 21000. loss_train: 8.87357616485118e-06 | loss_val: 2.9547619285330407e-05 | loss_test: 2.3233041436563723e-05 | \n",
      "Group 21500. loss_train: 2.2132237581316542e-05 | loss_val: 8.52388689522687e-05 | loss_test: 4.7031450886534995e-05 | \n",
      "Group 22000. loss_train: 1.5020847327491247e-05 | loss_val: 8.679875868458433e-05 | loss_test: 2.659588952044992e-05 | \n",
      "Group 22500. loss_train: 6.163364370121797e-06 | loss_val: 2.1601552680983707e-05 | loss_test: 1.323598735606189e-05 | \n",
      "Group 23000. loss_train: -3.1634387055393416e-06 | loss_val: 8.366055333515077e-05 | loss_test: -4.095989040084071e-05 | \n",
      "Group 23500. loss_train: 9.343951783016752e-06 | loss_val: 2.613319364731959e-05 | loss_test: 2.504238920153993e-05 | \n",
      "Group 24000. loss_train: 1.2681437804492698e-05 | loss_val: 5.804056457869792e-05 | loss_test: 2.6849246402502023e-05 | \n",
      "Group 24500. loss_train: -3.6859474949314536e-06 | loss_val: -2.777545331450061e-05 | loss_test: -1.9560921272878063e-06 | \n",
      "Group 25000. loss_train: 4.335921713488287e-06 | loss_val: 3.408992467025744e-05 | loss_test: 2.039451091173772e-06 | \n",
      "Group 25500. loss_train: 1.0319857947412177e-05 | loss_val: 2.299540518154379e-05 | loss_test: 2.5953642647394583e-05 | \n",
      "Group 26000. loss_train: 7.412966346697817e-06 | loss_val: 1.8677893646205034e-05 | loss_test: 1.8863691273017305e-05 | \n",
      "Group 26500. loss_train: 1.7693146937441264e-05 | loss_val: 0.00010336782856643145 | loss_test: 1.8731411021640277e-05 | \n",
      "Group 27000. loss_train: 4.197239875734692e-06 | loss_val: 1.4375889727029648e-05 | loss_test: 8.958112874645607e-06 | \n",
      "Group 27500. loss_train: 2.718224255163227e-06 | loss_val: 5.9392864509820346e-06 | loss_test: 7.105570167311367e-06 | \n",
      "Group 28000. loss_train: 2.472582770138879e-06 | loss_val: 1.556522125477514e-05 | loss_test: 1.8718013965693677e-06 | \n",
      "Group 28500. loss_train: 4.577405752833994e-06 | loss_val: 1.9285847748114918e-05 | loss_test: 7.937321317934181e-06 | \n",
      "Group 29000. loss_train: 1.998156467788267e-06 | loss_val: 1.57027550506908e-05 | loss_test: 4.497865195819252e-07 | \n",
      "Group 29500. loss_train: 1.0144250866694466e-05 | loss_val: 3.303042327081845e-05 | loss_test: 1.4681186401382272e-05 | \n",
      "Group 30000. loss_train: 4.4357982965962524e-06 | loss_val: 2.5589383623997096e-05 | loss_test: 3.964000933965637e-06 | \n",
      "Group 30500. loss_train: -1.8185147499997984e-06 | loss_val: -3.567717283493867e-05 | loss_test: 9.346366846759902e-06 | \n",
      "Group 31000. loss_train: 8.26517582333297e-07 | loss_val: 3.35297826238996e-05 | loss_test: -1.0130254462134159e-05 | \n",
      "Group 31500. loss_train: 2.311438889693804e-06 | loss_val: 2.3875916640250568e-05 | loss_test: -3.5537085274533164e-06 | \n",
      "Group 32000. loss_train: 6.3500386180883645e-06 | loss_val: 6.704731114645807e-06 | loss_test: 1.3625005681751604e-05 | \n",
      "Group 32500. loss_train: 4.933841574154358e-06 | loss_val: 4.197557267236406e-06 | loss_test: 1.0512129728946664e-05 | \n",
      "Group 33000. loss_train: 3.1751477541220516e-06 | loss_val: 2.0052483663698502e-05 | loss_test: -8.57645188102024e-07 | \n",
      "Group 33500. loss_train: 3.709068801645781e-06 | loss_val: 2.0550370772444276e-05 | loss_test: -1.1725790560533684e-06 | \n",
      "Group 34000. loss_train: 9.297500659145914e-07 | loss_val: 1.9550135820115338e-05 | loss_test: -6.51019341323704e-06 | \n",
      "Group 34500. loss_train: 1.6610691817377873e-06 | loss_val: -4.747820375877806e-07 | loss_test: 3.427182954823483e-06 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 35000. loss_train: 4.6851877857046184e-06 | loss_val: 2.5629172431410382e-06 | loss_test: 8.32291462917972e-06 | \n",
      "Group 35500. loss_train: 1.7907517698753272e-06 | loss_val: 1.8877702969357175e-07 | loss_test: 2.718261302378301e-06 | \n",
      "Group 36000. loss_train: 1.6879942892338672e-06 | loss_val: 6.671843399417533e-07 | loss_test: 1.5107210355696891e-06 | \n",
      "Group 36500. loss_train: 1.0894659295898228e-06 | loss_val: 9.173750279869276e-06 | loss_test: -5.497850186682421e-06 | \n",
      "Group 37000. loss_train: 1.1116816909939247e-06 | loss_val: -2.4944049858227417e-06 | loss_test: 6.837285388109242e-07 | \n",
      "Group 37500. loss_train: 1.7696305908256723e-07 | loss_val: 8.073800597345831e-06 | loss_test: -6.053958701800663e-06 | \n",
      "Group 38000. loss_train: -9.8498614722493e-08 | loss_val: 4.402115527340653e-06 | loss_test: -2.705834503785823e-06 | \n"
     ]
    }
   ],
   "source": [
    "# Split the dataset in a grouped and stratified manner\n",
    "\n",
    "def StratifiedGroupShuffleSplit(df_main):\n",
    "\n",
    "    df_main = df_main.reindex(np.random.permutation(df_main.index)) # shuffle dataset\n",
    "\n",
    "    # create empty train, val and test datasets\n",
    "    df_train = pd.DataFrame()\n",
    "    df_val = pd.DataFrame()\n",
    "    df_test = pd.DataFrame()\n",
    "\n",
    "    hparam_mse_wgt = 0.1 # must be between 0 and 1\n",
    "    assert(0 <= hparam_mse_wgt <= 1)\n",
    "    train_proportion = 0.8 # must be between 0 and 1\n",
    "    assert(0 <= train_proportion <= 1)\n",
    "    val_test_proportion = (1-train_proportion)/2\n",
    "\n",
    "    #subject_grouped_df = pd.concat([g for _, g in df_main.groupby(['subject_id'], sort=False, as_index=False)], ignore_index=True)\n",
    "    subject_grouped_df_main = df_main.groupby(['subject_id'], sort=False, as_index=False)\n",
    "    category_grouped_df_main = df_main.groupby('category').count()[['subject_id']]/len(df_main)*100\n",
    "\n",
    "    def calc_mse_loss(df):\n",
    "        grouped_df = df.groupby('category').count()[['subject_id']]/len(df)*100\n",
    "        df_temp = category_grouped_df_main.join(grouped_df, on = 'category', how = 'left', lsuffix = '_main')\n",
    "        df_temp.fillna(0, inplace=True)\n",
    "        df_temp['diff'] = (df_temp['subject_id_main'] - df_temp['subject_id'])**2\n",
    "        mse_loss = np.mean(df_temp['diff'])\n",
    "        return mse_loss\n",
    "    \n",
    "    len_train = 0\n",
    "    len_val = 0\n",
    "    len_test = 0\n",
    "    total_records = 0\n",
    "    i = 0\n",
    "    for _, group in subject_grouped_df_main:\n",
    "        \n",
    "        total_records = len_train + len_val + len_test\n",
    "        g = pd.DataFrame(group)\n",
    "        i += 1\n",
    "        \n",
    "        if (i < 4):\n",
    "            if (i == 1):\n",
    "                df_train = df_train.append(g, ignore_index=True)\n",
    "                len_train += len(g)\n",
    "                continue\n",
    "            elif (i == 2):\n",
    "                df_val = df_val.append(g, ignore_index=True)\n",
    "                len_val += len(g)\n",
    "                continue\n",
    "            else:\n",
    "                df_test = df_test.append(g, ignore_index=True)\n",
    "                len_test += len(g)\n",
    "                continue\n",
    "        \n",
    "        if (i % 500 != 0):\n",
    "            \n",
    "            if (train_proportion > (len_train/total_records)):\n",
    "                df_train = df_train.append(g, ignore_index=True)\n",
    "                len_train += len(g)\n",
    "            elif (val_test_proportion > (len_val/total_records)):\n",
    "                df_val = df_val.append(g, ignore_index=True)\n",
    "                len_val += len(g)\n",
    "            else:\n",
    "                df_test = df_test.append(g, ignore_index=True)\n",
    "                len_test += len(g)\n",
    "        else :\n",
    "            \n",
    "            mse_loss_diff_train = calc_mse_loss(df_train) - calc_mse_loss(df_train.append(g, ignore_index=True))\n",
    "            mse_loss_diff_val = calc_mse_loss(df_val) - calc_mse_loss(df_val.append(g, ignore_index=True))\n",
    "            mse_loss_diff_test = calc_mse_loss(df_test) - calc_mse_loss(df_test.append(g, ignore_index=True))\n",
    "\n",
    "            len_diff_train = (train_proportion - (len_train/total_records))\n",
    "            len_diff_val = (val_test_proportion - (len_val/total_records))\n",
    "            len_diff_test = (val_test_proportion - (len_test/total_records)) \n",
    "\n",
    "            len_loss_diff_train = len_diff_train * abs(len_diff_train)\n",
    "            len_loss_diff_val = len_diff_val * abs(len_diff_val)\n",
    "            len_loss_diff_test = len_diff_test * abs(len_diff_test)\n",
    "\n",
    "            loss_train = (hparam_mse_wgt * mse_loss_diff_train) + ((1-hparam_mse_wgt) * len_loss_diff_train)\n",
    "            loss_val = (hparam_mse_wgt * mse_loss_diff_val) + ((1-hparam_mse_wgt) * len_loss_diff_val)\n",
    "            loss_test = (hparam_mse_wgt * mse_loss_diff_test) + ((1-hparam_mse_wgt) * len_loss_diff_test)\n",
    "\n",
    "            if (max(loss_train,loss_val,loss_test) == loss_train):\n",
    "                df_train = df_train.append(g, ignore_index=True)\n",
    "                len_train += len(g)\n",
    "            elif (max(loss_train,loss_val,loss_test) == loss_val):\n",
    "                df_val = df_val.append(g, ignore_index=True)\n",
    "                len_val += len(g)\n",
    "            else:\n",
    "                df_test = df_test.append(g, ignore_index=True)\n",
    "                len_test += len(g)\n",
    "            \n",
    "            print (\"Group \" + str(i) + \". loss_train: \" + str(loss_train) + \" | \" + \"loss_val: \" + str(loss_val) + \" | \" + \"loss_test: \" + str(loss_test) + \" | \")\n",
    "        \n",
    "        if (i % 100 == 0 & i %1000 != 0):\n",
    "            print (\"Group \" + str(i))\n",
    "            \n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "src_train, src_val, src_test = StratifiedGroupShuffleSplit(df_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331556\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id_main</th>\n",
       "      <th>subject_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Case Management</th>\n",
       "      <td>0.058331</td>\n",
       "      <td>0.049765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consult</th>\n",
       "      <td>0.005912</td>\n",
       "      <td>0.002714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharge summary</th>\n",
       "      <td>3.342068</td>\n",
       "      <td>3.346644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECG</th>\n",
       "      <td>12.571904</td>\n",
       "      <td>12.755613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Echo</th>\n",
       "      <td>2.689748</td>\n",
       "      <td>2.717490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General</th>\n",
       "      <td>0.500731</td>\n",
       "      <td>0.475636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nursing</th>\n",
       "      <td>13.485296</td>\n",
       "      <td>13.090398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nursing/other</th>\n",
       "      <td>25.218365</td>\n",
       "      <td>25.725368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nutrition</th>\n",
       "      <td>0.568111</td>\n",
       "      <td>0.547720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pharmacy</th>\n",
       "      <td>0.006213</td>\n",
       "      <td>0.004223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physician</th>\n",
       "      <td>8.543012</td>\n",
       "      <td>8.189265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radiology</th>\n",
       "      <td>30.607090</td>\n",
       "      <td>30.786956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rehab Services</th>\n",
       "      <td>0.327608</td>\n",
       "      <td>0.329658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Respiratory</th>\n",
       "      <td>1.914553</td>\n",
       "      <td>1.807839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social Work</th>\n",
       "      <td>0.161059</td>\n",
       "      <td>0.170710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   subject_id_main  subject_id\n",
       "category                                      \n",
       "Case Management           0.058331    0.049765\n",
       "Consult                   0.005912    0.002714\n",
       "Discharge summary         3.342068    3.346644\n",
       "ECG                      12.571904   12.755613\n",
       "Echo                      2.689748    2.717490\n",
       "General                   0.500731    0.475636\n",
       "Nursing                  13.485296   13.090398\n",
       "Nursing/other            25.218365   25.725368\n",
       "Nutrition                 0.568111    0.547720\n",
       "Pharmacy                  0.006213    0.004223\n",
       "Physician                 8.543012    8.189265\n",
       "Radiology                30.607090   30.786956\n",
       "Rehab Services            0.327608    0.329658\n",
       "Respiratory               1.914553    1.807839\n",
       "Social Work               0.161059    0.170710"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = src_test #  change to src_train/src_test/src_val to inspect length and stratification\n",
    "print (len(df))\n",
    "category_grouped_df_main = df_main.groupby('category').count()[['subject_id']]/len(df_main)*100\n",
    "grouped_df = df.groupby('category').count()[['subject_id']]/len(df)*100\n",
    "df_temp = category_grouped_df_main.join(grouped_df, on = 'category', how = 'left', lsuffix = '_main')\n",
    "df_temp.fillna(0, inplace=True)\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(331556, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shock , cardiogenic &lt;par&gt; Assessment : &lt;par&gt; R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a 57 yr old female who was admitted to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a 57 yr old female transfered from [ H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TITLE : &lt;par&gt; Chief Complaint : &lt;par&gt; 24 Hour ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a 57 yr old female who was admitted to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Shock , cardiogenic <par> Assessment : <par> R...\n",
       "1  This is a 57 yr old female who was admitted to...\n",
       "2  This is a 57 yr old female transfered from [ H...\n",
       "3  TITLE : <par> Chief Complaint : <par> 24 Hour ...\n",
       "4  This is a 57 yr old female who was admitted to..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_train = pd.DataFrame(src_train, columns = [\"text\"])\n",
    "tgt_val = pd.DataFrame(src_val, columns = [\"text\"])\n",
    "tgt_test = pd.DataFrame(src_test, columns = [\"text\"])\n",
    "print(tgt_test.shape)\n",
    "tgt_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code for splitting dataset\n",
    "----------------------------------------------------------------------------------------\n",
    "\n",
    "## Split the dataframe into Training, Validation and Test datasets\n",
    "\n",
    "### Separate data columns into x (input features) and y (output)\n",
    "src = df_main.to_numpy()\n",
    "tgt = df_main['text'].to_numpy()\n",
    "\n",
    "split_idx_train = int(0.8 * len(df_main)) # 80% training\n",
    "split_idx_val = int(0.9 * len(df_main)) # 10% eval, 10% test\n",
    "\n",
    "### Split data by rows into a training set and a validation set\n",
    "src_train = pd.DataFrame(src[:split_idx_train,:], columns=df_main.columns)\n",
    "src_val = pd.DataFrame(src[split_idx_train:split_idx_val,:], columns=df_main.columns)\n",
    "src_test = pd.DataFrame(src[split_idx_val:,:], columns=df_main.columns)\n",
    "\n",
    "tgt_train = pd.DataFrame(tgt[:split_idx_train], columns = [\"text\"])\n",
    "tgt_val = pd.DataFrame(tgt[split_idx_train:split_idx_val], columns = [\"text\"])\n",
    "tgt_test = pd.DataFrame(tgt[split_idx_val:], columns = [\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27854055, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>value</th>\n",
       "      <th>valueuom</th>\n",
       "      <th>flag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2101-10-12 16:07:00</td>\n",
       "      <td>7.39</td>\n",
       "      <td>units</td>\n",
       "      <td>None</td>\n",
       "      <td>pH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2101-10-12 18:17:00</td>\n",
       "      <td>ART</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SPECIMEN TYPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2101-10-12 18:17:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>mEq/L</td>\n",
       "      <td>None</td>\n",
       "      <td>Base Excess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2101-10-12 18:17:00</td>\n",
       "      <td>22</td>\n",
       "      <td>mEq/L</td>\n",
       "      <td>None</td>\n",
       "      <td>Calculated Total CO2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2101-10-12 18:17:00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>mmol/L</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>Free Calcium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id           charttime value valueuom      flag  \\\n",
       "0           3 2101-10-12 16:07:00  7.39    units      None   \n",
       "1           3 2101-10-12 18:17:00   ART     None      None   \n",
       "2           3 2101-10-12 18:17:00    -1    mEq/L      None   \n",
       "3           3 2101-10-12 18:17:00    22    mEq/L      None   \n",
       "4           3 2101-10-12 18:17:00  0.93   mmol/L  abnormal   \n",
       "\n",
       "                  label  \n",
       "0                    pH  \n",
       "1         SPECIMEN TYPE  \n",
       "2           Base Excess  \n",
       "3  Calculated Total CO2  \n",
       "4          Free Calcium  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lab items data\n",
    "\n",
    "df_labitems = pd.read_sql_query('''\n",
    "  SELECT l.subject_id, l.charttime, l.value, l.valueuom, l.flag, d.label\n",
    "  FROM labevents l\n",
    "  INNER JOIN d_labitems d \n",
    "  USING (itemid)\n",
    "  --LIMIT 20;\n",
    "''', cnx)\n",
    "print(df_labitems.shape)\n",
    "df_labitems.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4156450, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>startdate</th>\n",
       "      <th>enddate</th>\n",
       "      <th>drug</th>\n",
       "      <th>prod_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2175-06-11</td>\n",
       "      <td>2175-06-12</td>\n",
       "      <td>Tacrolimus</td>\n",
       "      <td>1mg Capsule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2175-06-11</td>\n",
       "      <td>2175-06-12</td>\n",
       "      <td>Warfarin</td>\n",
       "      <td>5mg Tablet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2175-06-11</td>\n",
       "      <td>2175-06-12</td>\n",
       "      <td>Heparin Sodium</td>\n",
       "      <td>25,000 unit Premix Bag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2175-06-11</td>\n",
       "      <td>2175-06-12</td>\n",
       "      <td>D5W</td>\n",
       "      <td>HEPARIN BASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2175-06-11</td>\n",
       "      <td>2175-06-12</td>\n",
       "      <td>Furosemide</td>\n",
       "      <td>20mg Tablet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  startdate    enddate            drug           prod_strength\n",
       "0           6 2175-06-11 2175-06-12      Tacrolimus             1mg Capsule\n",
       "1           6 2175-06-11 2175-06-12        Warfarin              5mg Tablet\n",
       "2           6 2175-06-11 2175-06-12  Heparin Sodium  25,000 unit Premix Bag\n",
       "3           6 2175-06-11 2175-06-12             D5W            HEPARIN BASE\n",
       "4           6 2175-06-11 2175-06-12      Furosemide             20mg Tablet"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prescriptions data\n",
    "\n",
    "df_prescriptions = pd.read_sql_query('''\n",
    "  SELECT subject_id, startdate, enddate, drug, prod_strength\n",
    "  FROM prescriptions\n",
    "  --LIMIT 20;\n",
    "''', cnx)\n",
    "print(df_prescriptions.shape)\n",
    "df_prescriptions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file(df, filename):\n",
    "\n",
    "    f= open(filename,\"w+\")\n",
    "    length = len(df)\n",
    "    for i, row in enumerate(df.itertuples()):\n",
    "        subject_id = row[1]\n",
    "        charttime = row[7]\n",
    "        chartdate = datetime.combine(row[5], datetime.min.time())\n",
    "        category = str(row[4])\n",
    "\n",
    "        if (pd.isna(charttime)):\n",
    "            if (category == \"Discharge summary\"):\n",
    "                cutoff = chartdate\n",
    "                chartdate = cutoff + timedelta(days=1)\n",
    "            else:\n",
    "                cutoff = chartdate - timedelta(days=1)\n",
    "\n",
    "            lab_items = df_labitems[(df_labitems.subject_id == subject_id) & \n",
    "                                    (df_labitems.charttime >= cutoff) &\n",
    "                                    (df_labitems.charttime < chartdate)]\n",
    "\n",
    "        else:\n",
    "            cutoff = charttime - timedelta(days=1)\n",
    "            lab_items = df_labitems[(df_labitems.subject_id == subject_id) & \n",
    "                                    (df_labitems.charttime >= cutoff) &\n",
    "                                    (df_labitems.charttime < charttime)]\n",
    "\n",
    "        prescriptions = df_prescriptions[(df_prescriptions.subject_id == subject_id) & \n",
    "                                        (df_prescriptions.startdate >= cutoff) &\n",
    "                                        (df_prescriptions.startdate < chartdate)]\n",
    "\n",
    "        lab_items_list = \"\"\n",
    "        lab_items_length = len(lab_items)\n",
    "        if (lab_items_length > 0):\n",
    "            for j, lab_row in enumerate(lab_items.itertuples()):\n",
    "                flag = \"\"\n",
    "                if (pd.isna(lab_row[5]) == False):\n",
    "                    flag = \" , \" + str(lab_row[5])\n",
    "\n",
    "                lab_items_list += str(lab_row[6]) + \" , \" + str(lab_row[3]) + \" , \" + str(lab_row[4]) + flag\n",
    "                if (j != (lab_items_length - 1)):\n",
    "                    lab_items_list += \" | \"\n",
    "\n",
    "        prescriptions_list = \"\"\n",
    "        prescriptions_length = len(prescriptions)\n",
    "        if (prescriptions_length > 0):\n",
    "            for j, pre_row in enumerate(prescriptions.itertuples()):\n",
    "                prescriptions_list += str(pre_row[4]) + \" , \" + str(pre_row[5])\n",
    "                if (j != (prescriptions_length - 1)):\n",
    "                    prescriptions_list += \" | \"\n",
    "\n",
    "        f.write(str(row[10]) + \" <H> \" + str(row[4]) + \" <T> \" + str(row[3]) + \" <G> \" + str(row[8]) + \" <A> \" + \n",
    "                prescriptions_list + \" <0> \" + lab_items_list + \" <1>\" + \"\\n\")\n",
    "\n",
    "        if ((i+1) % 10000 == 0):\n",
    "            print (\"{0:.0f}%\".format((i+1)*100/length))\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%\n",
      "0%\n",
      "0%\n",
      "0%\n",
      "1%\n",
      "1%\n",
      "1%\n",
      "1%\n",
      "1%\n",
      "1%\n",
      "1%\n",
      "1%\n",
      "1%\n",
      "1%\n",
      "2%\n",
      "2%\n",
      "2%\n",
      "2%\n",
      "2%\n",
      "2%\n",
      "2%\n",
      "2%\n",
      "2%\n",
      "2%\n",
      "3%\n",
      "3%\n",
      "3%\n",
      "3%\n",
      "3%\n",
      "3%\n",
      "3%\n",
      "3%\n",
      "3%\n",
      "3%\n",
      "4%\n",
      "4%\n",
      "4%\n",
      "4%\n",
      "4%\n",
      "4%\n",
      "4%\n",
      "4%\n",
      "4%\n",
      "4%\n",
      "5%\n",
      "5%\n",
      "5%\n",
      "5%\n",
      "5%\n",
      "5%\n",
      "5%\n",
      "5%\n",
      "5%\n",
      "5%\n",
      "6%\n",
      "6%\n",
      "6%\n",
      "6%\n",
      "6%\n",
      "6%\n",
      "6%\n",
      "6%\n",
      "6%\n",
      "7%\n",
      "7%\n",
      "7%\n",
      "7%\n",
      "7%\n",
      "7%\n",
      "7%\n",
      "7%\n",
      "7%\n",
      "7%\n",
      "8%\n",
      "8%\n",
      "8%\n",
      "8%\n",
      "8%\n",
      "8%\n",
      "8%\n",
      "8%\n",
      "8%\n",
      "8%\n",
      "9%\n",
      "9%\n",
      "9%\n",
      "9%\n",
      "9%\n",
      "9%\n",
      "9%\n",
      "9%\n",
      "9%\n",
      "9%\n",
      "10%\n",
      "10%\n",
      "10%\n",
      "10%\n",
      "10%\n",
      "10%\n",
      "10%\n",
      "10%\n",
      "10%\n",
      "10%\n",
      "11%\n",
      "11%\n",
      "11%\n",
      "11%\n",
      "11%\n",
      "11%\n",
      "11%\n",
      "11%\n",
      "11%\n",
      "11%\n",
      "12%\n",
      "12%\n",
      "12%\n",
      "12%\n",
      "12%\n",
      "12%\n",
      "12%\n",
      "12%\n",
      "12%\n",
      "12%\n",
      "13%\n",
      "13%\n",
      "13%\n",
      "13%\n",
      "13%\n",
      "13%\n",
      "13%\n",
      "13%\n",
      "13%\n",
      "13%\n",
      "14%\n",
      "14%\n",
      "14%\n",
      "14%\n",
      "14%\n",
      "14%\n",
      "14%\n",
      "14%\n",
      "14%\n",
      "14%\n",
      "15%\n",
      "15%\n",
      "15%\n",
      "15%\n",
      "15%\n",
      "15%\n",
      "15%\n",
      "15%\n",
      "15%\n",
      "15%\n",
      "16%\n",
      "16%\n",
      "16%\n",
      "16%\n",
      "16%\n",
      "16%\n",
      "16%\n",
      "16%\n",
      "16%\n",
      "16%\n",
      "17%\n",
      "17%\n",
      "17%\n",
      "17%\n",
      "17%\n",
      "17%\n",
      "17%\n",
      "17%\n",
      "17%\n",
      "17%\n",
      "18%\n",
      "18%\n",
      "18%\n",
      "18%\n",
      "18%\n",
      "18%\n",
      "18%\n",
      "18%\n",
      "18%\n",
      "18%\n",
      "19%\n",
      "19%\n",
      "19%\n",
      "19%\n",
      "19%\n",
      "19%\n",
      "19%\n",
      "19%\n",
      "19%\n",
      "20%\n",
      "20%\n",
      "20%\n",
      "20%\n",
      "20%\n",
      "20%\n",
      "20%\n",
      "20%\n",
      "20%\n",
      "20%\n",
      "21%\n",
      "21%\n",
      "21%\n",
      "21%\n",
      "21%\n",
      "21%\n",
      "21%\n",
      "21%\n",
      "21%\n",
      "21%\n",
      "22%\n",
      "22%\n",
      "22%\n",
      "22%\n",
      "22%\n",
      "22%\n",
      "22%\n",
      "22%\n",
      "22%\n",
      "22%\n",
      "23%\n",
      "23%\n",
      "23%\n",
      "23%\n",
      "23%\n",
      "23%\n",
      "23%\n",
      "23%\n",
      "23%\n",
      "23%\n",
      "24%\n",
      "24%\n",
      "24%\n",
      "24%\n",
      "24%\n",
      "24%\n",
      "24%\n",
      "24%\n",
      "24%\n",
      "24%\n",
      "25%\n",
      "25%\n",
      "25%\n",
      "25%\n",
      "25%\n",
      "25%\n",
      "25%\n",
      "25%\n",
      "25%\n",
      "25%\n",
      "26%\n",
      "26%\n",
      "26%\n",
      "26%\n",
      "26%\n",
      "26%\n",
      "26%\n",
      "26%\n",
      "26%\n",
      "26%\n",
      "27%\n",
      "27%\n",
      "27%\n",
      "27%\n",
      "27%\n",
      "27%\n",
      "27%\n",
      "27%\n",
      "27%\n",
      "28%\n",
      "28%\n",
      "28%\n",
      "28%\n",
      "28%\n",
      "28%\n",
      "28%\n",
      "28%\n",
      "28%\n",
      "28%\n",
      "29%\n",
      "29%\n",
      "29%\n",
      "29%\n",
      "29%\n",
      "29%\n",
      "29%\n",
      "29%\n",
      "29%\n",
      "29%\n",
      "30%\n",
      "30%\n",
      "30%\n",
      "30%\n",
      "30%\n",
      "30%\n",
      "30%\n",
      "30%\n",
      "30%\n",
      "30%\n",
      "31%\n",
      "31%\n",
      "31%\n",
      "31%\n",
      "31%\n",
      "31%\n",
      "31%\n",
      "31%\n",
      "31%\n",
      "31%\n",
      "32%\n",
      "32%\n",
      "32%\n",
      "32%\n",
      "32%\n",
      "32%\n",
      "32%\n",
      "32%\n",
      "32%\n",
      "32%\n",
      "33%\n",
      "33%\n",
      "33%\n",
      "33%\n",
      "33%\n",
      "33%\n",
      "33%\n",
      "33%\n",
      "33%\n",
      "33%\n",
      "34%\n",
      "34%\n",
      "34%\n",
      "34%\n",
      "34%\n",
      "34%\n",
      "34%\n",
      "34%\n",
      "34%\n",
      "34%\n",
      "35%\n",
      "35%\n",
      "35%\n",
      "35%\n",
      "35%\n",
      "35%\n",
      "35%\n",
      "35%\n",
      "35%\n",
      "35%\n",
      "36%\n",
      "36%\n",
      "36%\n",
      "36%\n"
     ]
    }
   ],
   "source": [
    "# save source files to disk\n",
    "\n",
    "create_file(src_train, \"/mimic/data/preprocessed/src-train.txt\")\n",
    "create_file(src_val, \"/mimic/data/preprocessed/src-val.txt\")\n",
    "create_file(src_test, \"/mimic/data/preprocessed/src-test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save target files to disk\n",
    "\n",
    "np.savetxt('/mimic/data/preprocessed/tgt-train.txt', tgt_train, fmt='%s', newline=os.linesep)\n",
    "np.savetxt('/mimic/data/preprocessed/tgt-val.txt', tgt_val, fmt='%s', newline=os.linesep)\n",
    "np.savetxt('/mimic/data/preprocessed/tgt-test.txt', tgt_test, fmt='%s', newline=os.linesep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
